{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "209fb905",
   "metadata": {},
   "source": [
    "import Basic Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66b3489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm\n",
    "# import tqdm as tqdm_module\n",
    "# tqdm_module.tqdm = tqdm  # ì „ì—­ tqdm êµì²´\n",
    "import importlib\n",
    "import json\n",
    "\n",
    "# Utils import (ëª¨ë“ˆí™”)\n",
    "from utils import create_dataloaders, CDMetrics, get_loss_fn, CDTrainer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6759fe0a",
   "metadata": {},
   "source": [
    "CUDA(GPU) í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a39f554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: 0\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ë‹¨ì¼ GPU ì‚¬ìš©\n",
    "GPU_ID = 0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_ID)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using GPU: {GPU_ID}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "# ë©€í‹° GPU ì‚¬ìš© \n",
    "# # GPU_IDS = [0, 1, 2, 3]  # ì‚¬ìš©í•  GPU ë¦¬ìŠ¤íŠ¸\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = ','.join(map(str, GPU_IDS))\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# USE_MULTI_GPU = len(GPU_IDS) > 1 and torch.cuda.device_count() > 1\n",
    "# print(f\"Using GPUs: {GPU_IDS}\")\n",
    "# print(f\"Available GPU count: {torch.cuda.device_count()}\")\n",
    "# if USE_MULTI_GPU:\n",
    "#     BATCH_SIZE = BATCH_SIZE * len(GPU_IDS)  # ë©€í‹° GPUì‹œ ë°°ì¹˜ í¬ê¸° ì¡°ì •\n",
    "#     print(f\"Adjusted batch size for multi-GPU: {BATCH_SIZE}\")\n",
    "# ì‹œë“œ ì„¤ì • (ì¬í˜„ê°€ëŠ¥ì„±)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d79a069",
   "metadata": {},
   "source": [
    "ë°ì´í„°ì…‹ & ëª¨ë¸ ë¦¬ìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1184ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"./dataset\"  # ì‹¬ë³¼ë¦­ ë§í¬ëœ ë°ì´í„°ì…‹ ë£¨íŠ¸ í´ë”\n",
    "DATASET_LIST = [\n",
    "    'LEVIR-CD+',\n",
    "    'WHU-CD',\n",
    "    'CLCD',\n",
    "    'CaBuAr-CD',\n",
    "    'S2Looking-CD',\n",
    "    'SEN1Floods11-CD'\n",
    "]\n",
    "\n",
    "MODEL_LIST = [\n",
    "    'A2Net',\n",
    "    'Changer',\n",
    "    'Change3D',\n",
    "    'STRobustNet',\n",
    "    'USSFC-Net'\n",
    "    # 'ChangeMamba',\n",
    "    # 'CDMamba',\n",
    "    # 'ChangeCLIP',\n",
    "    # 'EATDER'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0aa99c",
   "metadata": {},
   "source": [
    "##### ëª¨ë¸ & ë°ì´í„°ì…‹ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ea8458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset: LEVIR-CD+\n",
      "Test model: STRobustNet\n",
      "Using base version: True\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤í—˜í•  ë°ì´í„°ì…‹ ì„ íƒ\n",
    "test_dataset = 'LEVIR-CD+'  # LEVIR-CD+\n",
    "# test_dataset = DATASET_LIST[0]  # LEVIR-CD+\n",
    "\n",
    "# ì‹¤í—˜í•  ëª¨ë¸ ì„ íƒ\n",
    "test_model = 'STRobustNet'\n",
    "\n",
    "# True: ìµœì†Œ êµ¬í˜„, False: ì „ì²´ êµ¬í˜„\n",
    "use_base = True  \n",
    "\n",
    "print(f\"Test dataset: {test_dataset}\")\n",
    "if test_model not in MODEL_LIST:\n",
    "    raise ValueError(f\"Model {test_model} not in MODEL_LIST. Choose from: {MODEL_LIST}\")\n",
    "print(f\"Test model: {test_model}\")\n",
    "print(f\"Using base version: {use_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d2943",
   "metadata": {},
   "source": [
    "ì‹œë“œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1940def",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cffb5c5",
   "metadata": {},
   "source": [
    "##### ê³ ì • ë©”íŠ¸ë¦­ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a71c3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë¯¸ì§€ ì„¤ì •\n",
    "IMG_SIZE = 256 \n",
    "IN_CHANNELS = 3  # RGB\n",
    "OUT_CHANNELS = 1  # Binary change detection\n",
    "\n",
    "# í•™ìŠµ ì„¤ì •\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 4\n",
    "MAX_ITERATIONS = 100000  # ë°ì´í„°ì…‹ í¬ê¸°ì™€ ë¬´ê´€í•˜ê²Œ ê³ ì •\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49247ef",
   "metadata": {},
   "source": [
    "ëª¨ë¸ ë™ì  import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c244ab05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: STRobustNetBase\n"
     ]
    }
   ],
   "source": [
    "def get_model_class(model_name, use_base=False):\n",
    "    \"\"\"ëª¨ë¸ ë™ì  import - ìë™ ê²½ë¡œ ìƒì„±\"\"\"\n",
    "    \n",
    "    # ëª¨ë¸ëª…ì„ ì†Œë¬¸ìë¡œ ë³€í™˜\n",
    "    model_name_lower = model_name.lower()\n",
    "    \n",
    "    # base/fullì— ë”°ë¥¸ ê²½ë¡œ ë° í´ë˜ìŠ¤ëª… ìƒì„±\n",
    "    if use_base:\n",
    "        module_path = f'models.{model_name_lower}_base'\n",
    "        class_name = f'{model_name}Base'\n",
    "    else:\n",
    "        module_path = f'models.{model_name_lower}'\n",
    "        class_name = model_name\n",
    "    \n",
    "    try:\n",
    "        module = importlib.import_module(module_path)\n",
    "        return getattr(module, class_name)\n",
    "    except (ImportError, AttributeError) as e:\n",
    "        if use_base:\n",
    "            raise ImportError(f\"{model_name} base version not found at {module_path}.{class_name}: {e}\")\n",
    "        else:\n",
    "            # Full ë²„ì „ì´ ì—†ìœ¼ë©´ baseë¡œ í´ë°±\n",
    "            print(f\"Full version not found ({module_path}.{class_name}), falling back to base version\")\n",
    "            return get_model_class(model_name, use_base=True)\n",
    "\n",
    "ModelClass = get_model_class(test_model, use_base)\n",
    "print(f\"Loaded: {ModelClass.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a3b866e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configurations:\n",
      "  Test_model: STRobustNet\n",
      "  Optimizer: sgd\n",
      "  Learning rate: 0.01\n",
      "  Weight decay: 0.0005\n",
      "  Momentum: 0.9\n",
      "  Scheduler: linear\n"
     ]
    }
   ],
   "source": [
    "from configs import get_model_config\n",
    "\n",
    "model_config = get_model_config(test_model)\n",
    "\n",
    "optimizer = model_config['optimizer']\n",
    "learning_rate = model_config['learning_rate']\n",
    "weight_decay = model_config['weight_decay']\n",
    "betas = model_config['betas']\n",
    "eps = model_config['eps']\n",
    "scheduler = model_config['scheduler']\n",
    "momentum = model_config['momentum']\n",
    "\n",
    "print(f\"Model configurations:\")\n",
    "print(f\"  Test_model: {test_model}\")\n",
    "print(f\"  Optimizer: {optimizer}\")\n",
    "print(f\"  Learning rate: {learning_rate}\")\n",
    "print(f\"  Weight decay: {weight_decay}\")\n",
    "if betas:\n",
    "    print(f\"  Betas: {betas}\")\n",
    "if momentum:\n",
    "    print(f\"  Momentum: {momentum}\")\n",
    "print(f\"  Scheduler: {scheduler}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404bde24",
   "metadata": {},
   "source": [
    "ì˜µí‹°ë§ˆì´ì € ìƒì„± í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b464924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, config):\n",
    "    \"\"\"ëª¨ë¸ ì„¤ì •ì— ë”°ë¥¸ ì˜µí‹°ë§ˆì´ì € ìƒì„±\"\"\"\n",
    "    if config['optimizer'] == 'adam':\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(), \n",
    "            lr=config['learning_rate'],\n",
    "            betas=config['betas'],\n",
    "            eps=config['eps'],\n",
    "            weight_decay=config['weight_decay']\n",
    "        )\n",
    "    elif config['optimizer'] == 'adamw':\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=config['learning_rate'],\n",
    "            betas=config['betas'],\n",
    "            eps=config['eps'],\n",
    "            weight_decay=config['weight_decay']\n",
    "        )\n",
    "    elif config['optimizer'] == 'sgd':\n",
    "        optimizer = torch.optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=config['learning_rate'],\n",
    "            momentum=config['momentum'],\n",
    "            weight_decay=config['weight_decay']\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {config['optimizer']}\")\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae099f70",
   "metadata": {},
   "source": [
    "ì‹¤í—˜ í´ë” ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef46f343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment directory: experiments/LEVIR-CD+/STRobustNet\n"
     ]
    }
   ],
   "source": [
    "test_path = f\"experiments/{test_dataset}\"\n",
    "test_dir = Path(f\"{test_path}\")\n",
    "test_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_dir = Path(f\"{test_path}/{test_model}\")\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "checkpoint_dir = model_dir / \"checkpoints\"\n",
    "checkpoint_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Experiment directory: {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c888eff1",
   "metadata": {},
   "source": [
    "Iteration ê³„ì‚° \n",
    "MAX_ITERATIONS = 100000ì„ ê¸°ì¤€ìœ¼ë¡œ epoch ìˆ˜ ê³„ì‚°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b884fb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/LEVIR-CD+\n",
      "Dataset found: dataset/LEVIR-CD+\n",
      "  train: 10192 images\n",
      "  val: 1568 images\n",
      "  test: 4000 images\n",
      "\n",
      "Training iterations info:\n",
      "  Train samples: 10192\n",
      "  Iterations per epoch: 159\n",
      "  Total epochs: 628\n",
      "  Total iterations: 99852\n"
     ]
    }
   ],
   "source": [
    "dataset_path = Path(DATASET_ROOT) / test_dataset\n",
    "print(dataset_path)\n",
    "if dataset_path.exists():\n",
    "    print(f\"Dataset found: {dataset_path}\")\n",
    "    splits = ['train', 'val', 'test']\n",
    "    dataset_info = {}\n",
    "    \n",
    "    for split in splits:\n",
    "        split_path = dataset_path / split\n",
    "        if split_path.exists():\n",
    "            img_count = len(list((split_path / 't1').glob('*')))\n",
    "            dataset_info[split] = img_count\n",
    "            print(f\"  {split}: {img_count} images\")\n",
    "    \n",
    "    # Epoch ìˆ˜ ê³„ì‚° (MAX_ITERATIONS ê¸°ì¤€)\n",
    "    if 'train' in dataset_info:\n",
    "        train_samples = dataset_info['train']\n",
    "        iterations_per_epoch = train_samples // BATCH_SIZE\n",
    "        EPOCHS = MAX_ITERATIONS // iterations_per_epoch\n",
    "        \n",
    "        print(f\"\\nTraining iterations info:\")\n",
    "        print(f\"  Train samples: {train_samples}\")\n",
    "        print(f\"  Iterations per epoch: {iterations_per_epoch}\")\n",
    "        print(f\"  Total epochs: {EPOCHS}\")\n",
    "        print(f\"  Total iterations: {EPOCHS * iterations_per_epoch}\")\n",
    "else:\n",
    "    print(f\"Dataset not found: {dataset_path}\")\n",
    "    raise FileNotFoundError(f\"Dataset {test_dataset} not found at {dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ee328f",
   "metadata": {},
   "source": [
    "ë°ì´í„°ë¡œë” ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be47a397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10192 images from LEVIR-CD+/train\n",
      "Loaded 1568 images from LEVIR-CD+/val\n",
      "Loaded 4000 images from LEVIR-CD+/test\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    root_dir=DATASET_ROOT,\n",
    "    dataset_name=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af0aa62",
   "metadata": {},
   "source": [
    "ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2028263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/userHome/userhome4/kyoungmin/miniconda3/envs/cd_efficient/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/userHome/userhome4/kyoungmin/miniconda3/envs/cd_efficient/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /userHome/userhome4/kyoungmin/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 111MB/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'opt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2158523/3716795714.py\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m trainer = CDTrainer(\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'opt' is not defined"
     ]
    }
   ],
   "source": [
    "model = ModelClass(num_classes=1).to(DEVICE)\n",
    "criterion = get_loss_fn('bce_dice')\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì €\n",
    "if optimizer == 'adam':\n",
    "    opt = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "elif optimizer == 'adamw':\n",
    "    opt = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "elif optimizer == 'sgd':  # ğŸ”¥ ì¶”ê°€!\n",
    "    opt = torch.optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unknown optimizer: {optimizer}\")\n",
    "\n",
    "# ìŠ¤ì¼€ì¤„ëŸ¬\n",
    "sched = None\n",
    "if scheduler == 'cosine':\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=EPOCHS)\n",
    "\n",
    "# %% Trainer ìƒì„± ë° í•™ìŠµ\n",
    "trainer = CDTrainer(\n",
    "    model=model,\n",
    "    optimizer=opt,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    scheduler=sched\n",
    ")\n",
    "\n",
    "# í•™ìŠµ ì‹¤í–‰\n",
    "trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCHS,\n",
    "    val_interval=10,\n",
    "    save_interval=50\n",
    ")\n",
    "\n",
    "# %% í…ŒìŠ¤íŠ¸ ë° ì†ë„ ì¸¡ì •\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "test_metrics = trainer.test(test_loader)\n",
    "\n",
    "# ì¶”ë¡  ì†ë„\n",
    "speed_metrics = trainer.measure_inference_speed(test_loader)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "trainer.save_results(model_dir, test_model, test_dataset)\n",
    "\n",
    "# %% ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nModel Parameters: {total_params:,}\")\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼\n",
    "final_results = {\n",
    "    'model': test_model,\n",
    "    'base_version': use_base,\n",
    "    'dataset': test_dataset,\n",
    "    'test_metrics': test_metrics,\n",
    "    'speed_metrics': speed_metrics,\n",
    "    'parameters': total_params\n",
    "}\n",
    "\n",
    "with open(model_dir / 'final_results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "\n",
    "print(\"\\nâœ“ All completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7515e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cd_efficient",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
