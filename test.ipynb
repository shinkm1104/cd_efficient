{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "648a884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLOPs, Parameters, FPS, Inference Time 측정 추가\n",
    "\n",
    "# ============================================================\n",
    "# Cell 1: Import Modules\n",
    "# ============================================================\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "\n",
    "# FLOPs 계산용\n",
    "from thop import profile, clever_format\n",
    "\n",
    "# Utils import\n",
    "from utils import create_dataloaders, CDMetrics, get_loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3c6337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: 1\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 2: GPU 설정\n",
    "# ============================================================\n",
    "GPU_ID = 1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_ID)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using GPU: {GPU_ID}\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "388e143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 3: 실험 설정\n",
    "# ============================================================\n",
    "DATASET_ROOT = \"./dataset\"\n",
    "TEST_DATASET = 'LEVIR-CD+'\n",
    "\n",
    "TEST_MODEL = 'Change3D'  # 파일명 기준 (대소문자 구분 X, 하이픈 무시)\n",
    "\n",
    "# 실험할 클래스명 (해당 파일 내의 클래스)\n",
    "TEST_CLASS = 'Change3DX3D'  \n",
    "\n",
    "def normalize_model_name(model_name):\n",
    "    \"\"\"\n",
    "    모델명을 파일명으로 변환\n",
    "    'ST-Robust-Net' -> 'strobustnet'\n",
    "    'Change3D' -> 'change3d'\n",
    "    \"\"\"\n",
    "    return model_name.replace('-', '').lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0ab368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset: LEVIR-CD+\n",
      "Test model: Change3D\n",
      "Module: models.change3d\n",
      "Class: Change3DX3D\n"
     ]
    }
   ],
   "source": [
    "# 배치 크기\n",
    "BATCH_SIZE = 1\n",
    "NUM_WORKERS = 1\n",
    "IMG_SIZE = 256\n",
    "\n",
    "DATASET_ROOT = \"./dataset\"\n",
    "\n",
    "model_file = normalize_model_name(TEST_MODEL)\n",
    "model_class = TEST_CLASS\n",
    "\n",
    "print(f\"Test dataset: {TEST_DATASET}\")\n",
    "print(f\"Test model: {TEST_MODEL}\")\n",
    "print(f\"Module: models.{model_file}\")\n",
    "print(f\"Class: {model_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb94ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment directory: experiments/LEVIR-CD+/Change3D_Change3DX3D\n",
      "Checkpoint path: experiments/LEVIR-CD+/Change3D_Change3DX3D/checkpoints/best_model.pth\n"
     ]
    }
   ],
   "source": [
    "# 실험 이름: 모델명_클래스명 (클래스명이 모델명과 같으면 생략)\n",
    "if model_class.lower() == TEST_MODEL.lower().replace('-', ''):\n",
    "    experiment_name = TEST_MODEL\n",
    "else:\n",
    "    experiment_name = f\"{TEST_MODEL}_{model_class}\"\n",
    "\n",
    "exp_dir = Path(f\"experiments/{TEST_DATASET}/{experiment_name}\")\n",
    "checkpoint_dir = exp_dir / \"checkpoints\"\n",
    "best_model_path = checkpoint_dir / \"best_model.pth\"\n",
    "\n",
    "print(f\"Experiment directory: {exp_dir}\")\n",
    "print(f\"Checkpoint path: {best_model_path}\")\n",
    "\n",
    "if not best_model_path.exists():\n",
    "    # best_model.pth가 없으면 가장 최근 체크포인트 사용\n",
    "    import glob\n",
    "    checkpoints = sorted(glob.glob(str(checkpoint_dir / \"checkpoint_epoch_*.pth\")))\n",
    "    if checkpoints:\n",
    "        best_model_path = Path(checkpoints[-1])\n",
    "        print(f\"Best model not found, using latest checkpoint: {best_model_path.name}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No checkpoints found in {checkpoint_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc83d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded: Change3DX3D from models.change3d\n",
      "Loading pretrained weights from ./pretrained/Change3D/X3D_L.pyth...\n",
      "✅ Successfully loaded X3D-L pretrained weights\n",
      "   Loaded 1139/1141 parameters\n",
      "   Loaded blocks: ['0', '1', '2', '3', '4', '5']\n",
      "\n",
      "✓ Model loaded: Change3DX3D\n",
      "  Checkpoint: best_model.pth\n",
      "  Epoch: 90\n",
      "  Best F1: 0.7356\n",
      "  Best IoU: 0.5818\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 모델 동적 import\n",
    "# ============================\n",
    "def get_model_class(module_name, class_name):\n",
    "    \"\"\"모델 동적 import\"\"\"\n",
    "    module_path = f'models.{module_name}'\n",
    "    \n",
    "    try:\n",
    "        module = importlib.import_module(module_path)\n",
    "        model_class = getattr(module, class_name)\n",
    "        print(f\"✅ Successfully loaded: {class_name} from {module_path}\")\n",
    "        return model_class\n",
    "    except ImportError as e:\n",
    "        print(f\"❌ Cannot import module {module_path}\")\n",
    "        raise ImportError(f\"Module import failed: {e}\")\n",
    "    except AttributeError as e:\n",
    "        print(f\"❌ Class {class_name} not found in {module_path}\")\n",
    "        # 사용 가능한 클래스 목록 출력\n",
    "        try:\n",
    "            module = importlib.import_module(module_path)\n",
    "            available_classes = [name for name in dir(module) \n",
    "                               if not name.startswith('_') and \n",
    "                               name[0].isupper()]\n",
    "            print(f\"   Available classes: {available_classes}\")\n",
    "        except:\n",
    "            pass\n",
    "        raise AttributeError(f\"Class not found: {e}\")\n",
    "\n",
    "# ============================\n",
    "# 모델 로드\n",
    "# ============================\n",
    "ModelClass = get_model_class(model_file, model_class)\n",
    "model = ModelClass(num_classes=1).to(DEVICE)\n",
    "\n",
    "# 체크포인트 로드\n",
    "checkpoint = torch.load(best_model_path, map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"\\n✓ Model loaded: {ModelClass.__name__}\")\n",
    "print(f\"  Checkpoint: {best_model_path.name}\")\n",
    "print(f\"  Epoch: {checkpoint.get('epoch', 'unknown')}\")\n",
    "if 'best_f1' in checkpoint:\n",
    "    print(f\"  Best F1: {checkpoint.get('best_f1', 0):.4f}\")\n",
    "if 'best_iou' in checkpoint:\n",
    "    print(f\"  Best IoU: {checkpoint.get('best_iou', 0):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7efdf9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Model Complexity Analysis\n",
      "============================================================\n",
      "  Total Parameters:      5,004,985\n",
      "  Trainable Parameters:  5,004,985\n",
      "  Parameters (M):        5.00 M\n",
      "  Model Size:            19.09 MB (FP32)\n",
      "\n",
      "  FLOPs:                 9,652,329,184.0\n",
      "  FLOPs (G):             9.65 G\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 6: 모델 복잡도 측정 (Parameters & FLOPs)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Model Complexity Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Parameters 계산\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Parameters (M)\n",
    "params_m = total_params / 1e6\n",
    "\n",
    "# Model Size (MB)\n",
    "model_size_mb = total_params * 4 / 1024 / 1024\n",
    "\n",
    "print(f\"  Total Parameters:      {total_params:,}\")\n",
    "print(f\"  Trainable Parameters:  {trainable_params:,}\")\n",
    "print(f\"  Parameters (M):        {params_m:.2f} M\")\n",
    "print(f\"  Model Size:            {model_size_mb:.2f} MB (FP32)\")\n",
    "\n",
    "# FLOPs 계산\n",
    "input_img1 = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(DEVICE)\n",
    "input_img2 = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(DEVICE)\n",
    "\n",
    "try:\n",
    "    flops, params = profile(model, inputs=(input_img1, input_img2), verbose=False)\n",
    "    flops_g = flops / 1e9  # GFLOPs\n",
    "    \n",
    "    print(f\"\\n  FLOPs:                 {flops:,}\")\n",
    "    print(f\"  FLOPs (G):             {flops_g:.2f} G\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n  FLOPs calculation failed: {e}\")\n",
    "    flops = 0\n",
    "    flops_g = 0\n",
    "\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a3d5616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10192 images from LEVIR-CD+/train\n",
      "Loaded 1568 images from LEVIR-CD+/val\n",
      "Loaded 4000 images from LEVIR-CD+/test\n",
      "\n",
      "Test batches: 4000\n",
      "Total test samples: 4000\n",
      "Loss function: BCEDiceLoss\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 7: 데이터로더 생성\n",
    "# ============================================================\n",
    "_, _, test_loader = create_dataloaders(\n",
    "    root_dir=DATASET_ROOT,\n",
    "    dataset_name=TEST_DATASET,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    img_size=IMG_SIZE,\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "print(f\"\\nTest batches: {len(test_loader)}\")\n",
    "print(f\"Total test samples: {len(test_loader.dataset)}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 8: 손실 함수\n",
    "# ============================================================\n",
    "criterion = get_loss_fn('bce_dice')\n",
    "print(\"Loss function: BCEDiceLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed9f7185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Inference Speed Measurement\n",
      "============================================================\n",
      "\n",
      "Warming up GPU (this may take a while)...\n",
      "✓ Warmup complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 9: 추론 속도 측정 (강화된 Warmup + 안정화)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Inference Speed Measurement\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================\n",
    "# 1. 강화된 Warmup (매우 중요!)\n",
    "# ============================================================\n",
    "print(\"\\nWarming up GPU (this may take a while)...\")\n",
    "\n",
    "warmup_batch = next(iter(test_loader))\n",
    "img1_warmup = warmup_batch['img1'].to(DEVICE)\n",
    "img2_warmup = warmup_batch['img2'].to(DEVICE)\n",
    "\n",
    "# 첫 실행 (메모리 할당)\n",
    "with torch.no_grad():\n",
    "    _ = model(img1_warmup, img2_warmup)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# 충분한 Warmup (최소 50회!)\n",
    "for _ in range(50):\n",
    "    with torch.no_grad():\n",
    "        _ = model(img1_warmup, img2_warmup)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# GPU 안정화 대기\n",
    "time.sleep(2)\n",
    "\n",
    "print(\"✓ Warmup complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a33509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Single Image Inference Speed\n",
      "------------------------------------------------------------\n",
      "Test image shape: torch.Size([1, 3, 256, 256])\n",
      "  Progress: 50/300 iterations\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 10: 단일 이미지 추론 속도 측정 (1개 이미지로 고정)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Single Image Inference Speed\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# 측정 설정\n",
    "num_iterations = 300\n",
    "single_times = []\n",
    "\n",
    "# 테스트 이미지 준비 (1개만!)\n",
    "test_iter = iter(test_loader)\n",
    "test_batch = next(test_iter)\n",
    "test_img1 = test_batch['img1'][0:1].to(DEVICE)  # [1, 3, 256, 256]\n",
    "test_img2 = test_batch['img2'][0:1].to(DEVICE)  # [1, 3, 256, 256]\n",
    "\n",
    "print(f\"Test image shape: {test_img1.shape}\")\n",
    "\n",
    "# 같은 이미지로 반복 측정\n",
    "for i in range(num_iterations):\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(test_img1, test_img2)\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    elapsed = time.perf_counter() - start\n",
    "    single_times.append(elapsed)\n",
    "    \n",
    "    # 진행상황 (10회마다)\n",
    "    if (i + 1) % 50 == 0:\n",
    "        print(f\"  Progress: {i+1}/{num_iterations} iterations\")\n",
    "\n",
    "# numpy 배열로 변환\n",
    "single_times = np.array(single_times)\n",
    "\n",
    "print(f\"\\nInitial measurements: {len(single_times)}\")\n",
    "print(f\"Raw statistics:\")\n",
    "print(f\"  Mean: {np.mean(single_times)*1000:.3f} ms\")\n",
    "print(f\"  Std:  {np.std(single_times)*1000:.3f} ms\")\n",
    "print(f\"  Min:  {np.min(single_times)*1000:.3f} ms\")\n",
    "print(f\"  Max:  {np.max(single_times)*1000:.3f} ms\")\n",
    "print(f\"  CV:   {(np.std(single_times)/np.mean(single_times))*100:.2f}%\")\n",
    "\n",
    "# 이상치 제거 (IQR method)\n",
    "Q1 = np.percentile(single_times, 25)\n",
    "Q3 = np.percentile(single_times, 75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "mask = (single_times >= lower_bound) & (single_times <= upper_bound)\n",
    "filtered_times = single_times[mask]\n",
    "\n",
    "num_outliers = len(single_times) - len(filtered_times)\n",
    "\n",
    "print(f\"\\nAfter outlier removal: {len(filtered_times)}\")\n",
    "print(f\"Outliers removed: {num_outliers}\")\n",
    "\n",
    "# === 시간 통계 ===\n",
    "mean_time_sec = np.mean(filtered_times)\n",
    "std_time_sec = np.std(filtered_times)\n",
    "median_time_sec = np.median(filtered_times)\n",
    "min_time_sec = np.min(filtered_times)\n",
    "max_time_sec = np.max(filtered_times)\n",
    "\n",
    "# ms 변환\n",
    "inference_time_ms = mean_time_sec * 1000\n",
    "inference_time_std_ms = std_time_sec * 1000\n",
    "median_time_ms = median_time_sec * 1000\n",
    "min_time_ms = min_time_sec * 1000\n",
    "max_time_ms = max_time_sec * 1000\n",
    "\n",
    "# CV (변동계수)\n",
    "cv_percent = (std_time_sec / mean_time_sec) * 100\n",
    "\n",
    "# === FPS 통계 ===\n",
    "fps_list = 1.0 / filtered_times\n",
    "fps_mean = np.mean(fps_list)\n",
    "fps_std = np.std(fps_list)\n",
    "fps_median = np.median(fps_list)\n",
    "fps_min = np.min(fps_list)\n",
    "fps_max = np.max(fps_list)\n",
    "\n",
    "# 최종 출력\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"{'FINAL STATISTICS':^60}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\nInference Time (ms):\")\n",
    "print(f\"  Mean:   {inference_time_ms:.3f} ± {inference_time_std_ms:.3f} ms\")\n",
    "print(f\"  Median: {median_time_ms:.3f} ms\")\n",
    "print(f\"  Range:  [{min_time_ms:.3f}, {max_time_ms:.3f}] ms\")\n",
    "print(f\"  CV:     {cv_percent:.2f}%\")\n",
    "\n",
    "print(f\"\\nFrame Per Second (FPS):\")\n",
    "print(f\"  Mean:   {fps_mean:.2f} ± {fps_std:.2f}\")\n",
    "print(f\"  Median: {fps_median:.2f}\")\n",
    "print(f\"  Range:  [{fps_min:.2f}, {fps_max:.2f}]\")\n",
    "\n",
    "# 품질 체크\n",
    "print(f\"\\n{'Quality Check':^60}\")\n",
    "if cv_percent < 10:\n",
    "    print(f\"  ✓ Excellent (CV < 10%)\")\n",
    "elif cv_percent < 20:\n",
    "    print(f\"  ⚠ Acceptable (10% ≤ CV < 20%)\")\n",
    "else:\n",
    "    print(f\"  ✗ Poor (CV ≥ 20%) - Consider re-measuring\")\n",
    "    print(f\"    Possible causes:\")\n",
    "    print(f\"    - Other GPU processes\")\n",
    "    print(f\"    - Thermal throttling\")\n",
    "    print(f\"    - Insufficient warmup\")\n",
    "\n",
    "print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf2cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Batch Inference Speed\n",
      "------------------------------------------------------------\n",
      "  Batch size:        1\n",
      "  Iterations:        20\n",
      "  Avg batch time:    24.15 ms\n",
      "  Batch FPS:         41.40 images/sec\n",
      "  Per image:         24.15 ms\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 11: 배치 추론 속도 측정\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Batch Inference Speed\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# 배치 단위로 20회 측정\n",
    "num_batch_iterations = 20\n",
    "batch_times = []\n",
    "\n",
    "test_iter = iter(test_loader)\n",
    "\n",
    "for _ in range(num_batch_iterations):\n",
    "    try:\n",
    "        batch = next(test_iter)\n",
    "    except StopIteration:\n",
    "        test_iter = iter(test_loader)\n",
    "        batch = next(test_iter)\n",
    "    \n",
    "    img1 = batch['img1'].to(DEVICE)\n",
    "    img2 = batch['img2'].to(DEVICE)\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _ = model(img1, img2)\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    batch_times.append(time.time() - start)\n",
    "\n",
    "# 통계\n",
    "batch_times = np.array(batch_times)\n",
    "avg_batch_time = np.mean(batch_times)\n",
    "batch_fps = BATCH_SIZE / avg_batch_time\n",
    "batch_per_image = avg_batch_time / BATCH_SIZE\n",
    "\n",
    "print(f\"  Batch size:        {BATCH_SIZE}\")\n",
    "print(f\"  Iterations:        {num_batch_iterations}\")\n",
    "print(f\"  Avg batch time:    {avg_batch_time*1000:.2f} ms\")\n",
    "print(f\"  Batch FPS:         {batch_fps:.2f} images/sec\")\n",
    "print(f\"  Per image:         {batch_per_image*1000:.2f} ms\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb44f5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing on Full Test Set\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 4000/4000 [01:36<00:00, 41.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                        Test Results                        \n",
      "============================================================\n",
      "  Loss:      0.1547\n",
      "  F1 Score:  0.7711\n",
      "  Precision: 0.7581\n",
      "  Recall:    0.7846\n",
      "  IoU:       0.6275\n",
      "  Kappa:     0.7611\n",
      "  OA:        0.9809\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 12: 테스트 세트 평가\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Testing on Full Test Set\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_metrics = CDMetrics()\n",
    "test_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Testing'):\n",
    "        img1 = batch['img1'].to(DEVICE)\n",
    "        img2 = batch['img2'].to(DEVICE)\n",
    "        label = batch['label'].to(DEVICE)\n",
    "        \n",
    "        # 추론\n",
    "        output = model(img1, img2)\n",
    "        \n",
    "        # Loss\n",
    "        loss = criterion(output, label)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # 메트릭 업데이트\n",
    "        test_metrics.update(output, label)\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_results = test_metrics.get_metrics()\n",
    "\n",
    "print(f\"\\n{'Test Results':^60}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  Loss:      {avg_test_loss:.4f}\")\n",
    "print(f\"  F1 Score:  {test_results['f1']:.4f}\")\n",
    "print(f\"  Precision: {test_results['precision']:.4f}\")\n",
    "print(f\"  Recall:    {test_results['recall']:.4f}\")\n",
    "print(f\"  IoU:       {test_results['iou']:.4f}\")\n",
    "print(f\"  Kappa:     {test_results['kappa']:.4f}\")\n",
    "print(f\"  OA:        {test_results['oa']:.4f}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d06d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                       SUMMARY TABLE                        \n",
      "============================================================\n",
      "Metric                                        Value\n",
      "------------------------------------------------------------\n",
      "Model                                      Change3D\n",
      "Dataset                                   LEVIR-CD+\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'use_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_744477/1023135510.py\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{'Model':<30} {TEST_MODEL:>20}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{'Dataset':<30} {TEST_DATASET:>20}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{'Base Version':<30} {str(use_base):>20}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{'Model Parameters (M)':<30} {params_m:>19.2f} M\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'use_base' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 13: 결과 요약 테이블\n",
    "# ============================================================\n",
    "print(f\"\\n{'SUMMARY TABLE':^60}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Metric':<30} {'Value':>20}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Model':<30} {TEST_MODEL:>20}\")\n",
    "print(f\"{'Dataset':<30} {TEST_DATASET:>20}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Model Parameters (M)':<30} {params_m:>19.2f} M\")\n",
    "print(f\"{'FLOPs (G)':<30} {flops_g:>19.2f} G\")\n",
    "print(f\"{'Frame Per Second (FPS)':<30} {fps_mean:>15.2f} ± {fps_std:.2f}\")\n",
    "print(f\"{'Inference Time (ms)':<30} {inference_time_ms:>12.2f} ± {inference_time_std_ms:.2f}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'F1 Score':<30} {test_results['f1']:>20.4f}\")\n",
    "print(f\"{'IoU':<30} {test_results['iou']:>20.4f}\")\n",
    "print(f\"{'Precision':<30} {test_results['precision']:>20.4f}\")\n",
    "print(f\"{'Recall':<30} {test_results['recall']:>20.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85d64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Results saved to experiments/LEVIR-CD+/USSFCNet/test_results.json\n",
      "\n",
      "============================================================\n",
      "Quick Summary:\n",
      "============================================================\n",
      "F1 Score:              0.7786\n",
      "Precision:             0.7732\n",
      "Recall:                0.7841\n",
      "IoU:                   0.6375\n",
      "Kappa:                 0.7691\n",
      "Overall Accuracy:      0.9817\n",
      "------------------------------------------------------------\n",
      "Model Parameters (M):  5.57\n",
      "FLOPs (G):             3.69\n",
      "Inference Time (ms):   2.32 ± 0.10\n",
      "FPS:                   431.62 ± 17.94\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Test Complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Cell 14: 결과 저장\n",
    "# ============================================================\n",
    "results_dict = {\n",
    "    'model': TEST_MODEL,\n",
    "    'dataset': TEST_DATASET,\n",
    "    \n",
    "    # 핵심 지표 (논문 표준 단위)\n",
    "    'model_parameters_m': float(params_m),\n",
    "    'flops_g': float(flops_g),\n",
    "    'inference_time_ms': float(inference_time_ms),\n",
    "    'inference_time_std_ms': float(inference_time_std_ms),\n",
    "    'fps': float(fps_mean),\n",
    "    'fps_std': float(fps_std),\n",
    "    \n",
    "    # 상세 정보\n",
    "    'model_complexity': {\n",
    "        'total_params': int(total_params),\n",
    "        'trainable_params': int(trainable_params),\n",
    "        'params_m': float(params_m),\n",
    "        'flops': int(flops),\n",
    "        'flops_g': float(flops_g),\n",
    "        'model_size_mb': float(model_size_mb)\n",
    "    },\n",
    "    \n",
    "    'inference_speed': {\n",
    "        'inference_time_ms': float(inference_time_ms),\n",
    "        'inference_time_std_ms': float(inference_time_std_ms),\n",
    "        'inference_time_median_ms': float(median_time_ms),\n",
    "        'inference_time_min_ms': float(min_time_ms),\n",
    "        'inference_time_max_ms': float(max_time_ms),\n",
    "        'cv_percent': float(cv_percent),\n",
    "        'fps_mean': float(fps_mean),\n",
    "        'fps_std': float(fps_std),\n",
    "        'fps_median': float(fps_median),\n",
    "        'fps_min': float(fps_min),\n",
    "        'fps_max': float(fps_max),\n",
    "        'num_iterations': int(len(filtered_times)),\n",
    "        'num_outliers': int(num_outliers),\n",
    "        'batch_time_ms': float(avg_batch_time * 1000),\n",
    "        'batch_fps': float(batch_fps)\n",
    "    },\n",
    "    \n",
    "    'test_metrics': {\n",
    "        'loss': float(avg_test_loss),\n",
    "        'f1': float(test_results['f1']),\n",
    "        'iou': float(test_results['iou']),\n",
    "        'precision': float(test_results['precision']),\n",
    "        'recall': float(test_results['recall']),\n",
    "        'oa': float(test_results['oa']),\n",
    "        'kappa': float(test_results['kappa'])\n",
    "    }\n",
    "}\n",
    "\n",
    "# JSON 저장\n",
    "results_path = exp_dir / 'test_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results_dict, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Results saved to {results_path}\")\n",
    "\n",
    "# 간단한 요약\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Quick Summary:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"F1 Score:              {test_results['f1']:.4f}\")\n",
    "print(f\"Precision:             {test_results['precision']:.4f}\")\n",
    "print(f\"Recall:                {test_results['recall']:.4f}\")\n",
    "print(f\"IoU:                   {test_results['iou']:.4f}\")\n",
    "print(f\"Kappa:                 {test_results['kappa']:.4f}\")\n",
    "print(f\"Overall Accuracy:      {test_results['oa']:.4f}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"Model Parameters (M):  {params_m:.2f}\")\n",
    "print(f\"FLOPs (G):             {flops_g:.2f}\")\n",
    "print(f\"Inference Time (ms):   {inference_time_ms:.2f} ± {inference_time_std_ms:.2f}\")\n",
    "print(f\"FPS:                   {fps_mean:.2f} ± {fps_std:.2f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Test Complete!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cd_efficient",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
