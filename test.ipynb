{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efdf9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Inference & Speed Measurement\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'checkpoint_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4112517/491847571.py\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# %% Best 모델 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'best_model.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbest_model_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'checkpoint_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Jupyter Notebook: test.ipynb\n",
    "# 각 셀을 순서대로 실행하세요\n",
    "\n",
    "# ============================================================\n",
    "# Cell 1: Import Modules\n",
    "# ============================================================\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "\n",
    "# Utils import\n",
    "from utils import create_dataloaders, CDMetrics, get_loss_fn\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 2: GPU 설정\n",
    "# ============================================================\n",
    "# 단일 GPU 사용\n",
    "GPU_ID = 0\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(GPU_ID)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using GPU: {GPU_ID}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 3: 실험 설정\n",
    "# ============================================================\n",
    "# 데이터셋 설정\n",
    "DATASET_ROOT = \"./dataset\"\n",
    "test_dataset = 'LEVIR-CD+'\n",
    "\n",
    "# 모델 설정\n",
    "test_model = 'A2Net'\n",
    "use_base = True  # True: base version, False: full version\n",
    "\n",
    "# 배치 크기\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "IMG_SIZE = 256\n",
    "\n",
    "print(f\"Dataset: {test_dataset}\")\n",
    "print(f\"Model: {test_model}\")\n",
    "print(f\"Base version: {use_base}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 4: 경로 설정\n",
    "# ============================================================\n",
    "# 실험 디렉토리\n",
    "exp_dir = Path(f\"experiments/{test_dataset}/{test_model}\")\n",
    "checkpoint_dir = exp_dir / \"checkpoints\"\n",
    "best_model_path = checkpoint_dir / \"best_model.pth\"\n",
    "\n",
    "print(f\"Experiment directory: {exp_dir}\")\n",
    "print(f\"Checkpoint path: {best_model_path}\")\n",
    "\n",
    "if not best_model_path.exists():\n",
    "    raise FileNotFoundError(f\"Best model not found at {best_model_path}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 5: 모델 로드\n",
    "# ============================================================\n",
    "def get_model_class(model_name, use_base=False):\n",
    "    \"\"\"모델 동적 import\"\"\"\n",
    "    model_mapping = {\n",
    "        'A2Net': {\n",
    "            'base': ('models.a2net_base', 'A2NetBase'),\n",
    "            'full': ('models.a2net', 'A2Net')\n",
    "        },\n",
    "        'Change3D': {\n",
    "            'base': ('models.change3d_base', 'Change3DBase'),\n",
    "            'full': ('models.change3d', 'Change3D')\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    if model_name not in model_mapping:\n",
    "        raise ValueError(f\"Model {model_name} not implemented\")\n",
    "    \n",
    "    version = 'base' if use_base else 'full'\n",
    "    module_path, class_name = model_mapping[model_name][version]\n",
    "    \n",
    "    try:\n",
    "        module = importlib.import_module(module_path)\n",
    "        model_class = getattr(module, class_name)\n",
    "        return model_class\n",
    "    except ImportError:\n",
    "        if use_base:\n",
    "            raise ImportError(f\"{model_name} base version not found\")\n",
    "        else:\n",
    "            print(f\"Full version not found, falling back to base\")\n",
    "            return get_model_class(model_name, use_base=True)\n",
    "\n",
    "# 모델 생성\n",
    "ModelClass = get_model_class(test_model, use_base=use_base)\n",
    "model = ModelClass(num_classes=1).to(DEVICE)\n",
    "\n",
    "# 체크포인트 로드\n",
    "checkpoint = torch.load(best_model_path, map_location=DEVICE)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"\\n✓ Model loaded: {ModelClass.__name__}\")\n",
    "print(f\"  Epoch: {checkpoint.get('epoch', 'unknown')}\")\n",
    "print(f\"  Best F1: {checkpoint.get('best_f1', 0):.4f}\")\n",
    "print(f\"  Best IoU: {checkpoint.get('best_iou', 0):.4f}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 6: 데이터로더 생성\n",
    "# ============================================================\n",
    "# 테스트 데이터로더만 생성\n",
    "_, _, test_loader = create_dataloaders(\n",
    "    root_dir=DATASET_ROOT,\n",
    "    dataset_name=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    img_size=IMG_SIZE,\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "print(f\"Total test samples: {len(test_loader.dataset)}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 7: 손실 함수\n",
    "# ============================================================\n",
    "criterion = get_loss_fn('bce_dice')\n",
    "print(\"Loss function: BCEDiceLoss\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 8: 테스트 평가\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Testing on full test set\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_metrics = CDMetrics()\n",
    "test_loss = 0\n",
    "\n",
    "# 추론 시간 측정용\n",
    "inference_times = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Testing'):\n",
    "        img1 = batch['img1'].to(DEVICE)\n",
    "        img2 = batch['img2'].to(DEVICE)\n",
    "        label = batch['label'].to(DEVICE)\n",
    "        \n",
    "        # Loss 계산\n",
    "        output = model(img1, img2)\n",
    "        loss = criterion(output, label)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # 메트릭 업데이트\n",
    "        test_metrics.update(output, label)\n",
    "        \n",
    "        # 추론 시간 측정 (개별 샘플)\n",
    "        for i in range(img1.size(0)):\n",
    "            torch.cuda.synchronize()\n",
    "            \n",
    "            start_time = time.time()\n",
    "            _ = model(img1[i:i+1], img2[i:i+1])\n",
    "            \n",
    "            torch.cuda.synchronize()\n",
    "            \n",
    "            inference_times.append(time.time() - start_time)\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_results = test_metrics.get_metrics()\n",
    "\n",
    "print(f\"\\n{'Test Results':^60}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  Loss:      {avg_test_loss:.4f}\")\n",
    "print(f\"  F1 Score:  {test_results['f1']:.4f}\")\n",
    "print(f\"  IoU:       {test_results['iou']:.4f}\")\n",
    "print(f\"  Precision: {test_results['precision']:.4f}\")\n",
    "print(f\"  Recall:    {test_results['recall']:.4f}\")\n",
    "print(f\"  OA:        {test_results['oa']:.4f}\")\n",
    "print(f\"  Kappa:     {test_results['kappa']:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 9: 추론 속도 분석\n",
    "# ============================================================\n",
    "print(f\"\\n{'Inference Speed Analysis':^60}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "inference_times = np.array(inference_times)\n",
    "avg_time = np.mean(inference_times)\n",
    "std_time = np.std(inference_times)\n",
    "\n",
    "# FPS 계산\n",
    "fps = 1.0 / avg_time\n",
    "\n",
    "# 이미지당 처리 시간 (ms)\n",
    "inference_time_ms = avg_time * 1000\n",
    "\n",
    "print(f\"  Total samples:     {len(inference_times)}\")\n",
    "print(f\"  Inference Time:    {inference_time_ms:.2f} ms/image\")\n",
    "print(f\"  Std deviation:     {std_time*1000:.2f} ms\")\n",
    "print(f\"  FPS:               {fps:.2f} images/sec\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 10: 배치 단위 추론 속도\n",
    "# ============================================================\n",
    "print(f\"\\n{'Batch Inference Speed':^60}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Warmup\n",
    "warmup_batch = next(iter(test_loader))\n",
    "img1_warmup = warmup_batch['img1'].to(DEVICE)\n",
    "img2_warmup = warmup_batch['img2'].to(DEVICE)\n",
    "\n",
    "for _ in range(5):\n",
    "    with torch.no_grad():\n",
    "        _ = model(img1_warmup, img2_warmup)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# 실제 측정 (10 배치)\n",
    "num_measure_batches = min(10, len(test_loader))\n",
    "batch_times = []\n",
    "\n",
    "test_iter = iter(test_loader)\n",
    "for _ in range(num_measure_batches):\n",
    "    batch = next(test_iter)\n",
    "    img1 = batch['img1'].to(DEVICE)\n",
    "    img2 = batch['img2'].to(DEVICE)\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _ = model(img1, img2)\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    batch_times.append(time.time() - start)\n",
    "\n",
    "avg_batch_time = np.mean(batch_times)\n",
    "batch_fps = BATCH_SIZE / avg_batch_time\n",
    "single_image_time = avg_batch_time / BATCH_SIZE\n",
    "\n",
    "print(f\"  Batch size:        {BATCH_SIZE}\")\n",
    "print(f\"  Batches measured:  {num_measure_batches}\")\n",
    "print(f\"  Avg batch time:    {avg_batch_time*1000:.2f} ms\")\n",
    "print(f\"  Batch FPS:         {batch_fps:.2f} images/sec\")\n",
    "print(f\"  Per image:         {single_image_time*1000:.2f} ms\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 11: 모델 정보\n",
    "# ============================================================\n",
    "print(f\"\\n{'Model Information':^60}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"  Total parameters:      {total_params:,}\")\n",
    "print(f\"  Trainable parameters:  {trainable_params:,}\")\n",
    "print(f\"  Model size:            {total_params * 4 / 1024 / 1024:.2f} MB (FP32)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 12: 결과 저장\n",
    "# ============================================================\n",
    "results_dict = {\n",
    "    'model': test_model,\n",
    "    'dataset': test_dataset,\n",
    "    'test_metrics': {\n",
    "        'loss': float(avg_test_loss),\n",
    "        'f1': float(test_results['f1']),\n",
    "        'iou': float(test_results['iou']),\n",
    "        'precision': float(test_results['precision']),\n",
    "        'recall': float(test_results['recall']),\n",
    "        'oa': float(test_results['oa']),\n",
    "        'kappa': float(test_results['kappa'])\n",
    "    },\n",
    "    'inference_speed': {\n",
    "        'inference_time_ms': float(inference_time_ms),\n",
    "        'fps': float(fps),\n",
    "        'std_time_ms': float(std_time * 1000),\n",
    "        'batch_time_ms': float(avg_batch_time * 1000),\n",
    "        'batch_fps': float(batch_fps)\n",
    "    },\n",
    "    'model_info': {\n",
    "        'total_params': int(total_params),\n",
    "        'trainable_params': int(trainable_params),\n",
    "        'model_size_mb': float(total_params * 4 / 1024 / 1024)\n",
    "    }\n",
    "}\n",
    "\n",
    "# JSON 저장\n",
    "results_path = exp_dir / 'test_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results_dict, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Results saved to {results_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Test Complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Cell 13: 결과 요약\n",
    "# ============================================================\n",
    "print(f\"\\n{'SUMMARY':^60}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {test_model}\")\n",
    "print(f\"Dataset: {test_dataset}\")\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  F1: {test_results['f1']:.4f}\")\n",
    "print(f\"  IoU: {test_results['iou']:.4f}\")\n",
    "print(f\"\\nSpeed:\")\n",
    "print(f\"  Inference Time: {inference_time_ms:.2f} ms\")\n",
    "print(f\"  FPS: {fps:.2f}\")\n",
    "print(f\"\\nModel:\")\n",
    "print(f\"  Parameters: {total_params:,}\")\n",
    "print(f\"  Size: {total_params * 4 / 1024 / 1024:.2f} MB\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cd_efficient",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
