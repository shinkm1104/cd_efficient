"""
Change3D with X3D Backbone
X3D ë°±ë³¸ì„ ì‚¬ìš©í•œ ê°•ë ¥í•œ Video Modeling for Change Detection
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import os
from pathlib import Path

# X3D ë°±ë³¸ import
from models.x3d import create_x3d


class Change3DBase(nn.Module):
    """
    Change3D Base Class
    
    í•µì‹¬ ì•„ì´ë””ì–´:
    1. Perception Frame (í•™ìŠµ ê°€ëŠ¥í•œ "ê´€ì°°ì")
    2. X3D Backbone (ê°•ë ¥í•œ ë¹„ë””ì˜¤ íŠ¹ì§• ì¶”ì¶œ)
    3. Time ì°¨ì›ì—ì„œ Perception Feature ì¶”ì¶œ
    """
    
    def __init__(self, num_classes=1, width_factor=2.0, depth_factor=5.0, 
                 x3d_out_dim=192, version='l'):
        super(Change3DBase, self).__init__()
        
        self.version = version
        
        # ğŸ¯ í•µì‹¬ 1: Perception Frame
        self.perception_frame = nn.Parameter(
            torch.randn(1, 3, 256, 256) * 0.02
        )
        
        # ğŸ¯ í•µì‹¬ 2: X3D Backbone ì„¤ì •
        self.x3d = create_x3d(
            input_channel=3,
            input_clip_length=3,  # [I1, P, I2] = 3 frames
            input_crop_size=256,
            model_num_class=400,  # Kinetics-400 (ê°€ì¤‘ì¹˜ í˜¸í™˜ì„±)
            width_factor=width_factor,
            depth_factor=depth_factor,
            dropout_rate=0.5,
            head_output_with_global_average=False
        )
        
        # ğŸ”¥ ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°
        self.load_pretrained_weights(version)
        
        # X3Dì˜ head ì œê±° (ë°±ë³¸ë§Œ ì‚¬ìš©)
        self.x3d.blocks = self.x3d.blocks[:-1]  # classification head ì œê±°
        
        # ğŸ¯ í•µì‹¬ 3: ë³€í™” íƒì§€ í—¤ë“œ
        # Time ì°¨ì› ì²˜ë¦¬ë¥¼ ìœ„í•œ Conv3D
        self.temporal_conv = nn.Conv3d(
            x3d_out_dim, 256,
            kernel_size=(3, 1, 1),  # Timeì¶•ë§Œ ì²˜ë¦¬
            padding=(1, 0, 0)
        )
        
        # ìµœì¢… ë³€í™” ë§µ ìƒì„± í—¤ë“œ
        self.head = nn.Sequential(
            nn.Conv2d(256, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, num_classes, kernel_size=1)
        )
    
    def load_pretrained_weights(self, version='l'):
        """ì‚¬ì „í•™ìŠµëœ X3D ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°"""
        # ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ
        weight_path = f'./pretrained/Change3D/X3D_{version.upper()}.pyth'
        
        if not os.path.exists(weight_path):
            print(f"âš ï¸ Warning: Pretrained weights not found at {weight_path}")
            print("   Using random initialization")
            print(f"   Download weights from: https://dl.fbaipublicfiles.com/pytorchvideo/x3d/x3d_{version}.pyth")
            return
        
        try:
            print(f"Loading pretrained weights from {weight_path}...")
            
            # ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°
            checkpoint = torch.load(weight_path, map_location='cpu')
            
            # checkpoint êµ¬ì¡° í™•ì¸
            if isinstance(checkpoint, dict):
                if 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                elif 'model_state' in checkpoint:
                    state_dict = checkpoint['model_state']
                elif 'model' in checkpoint:
                    state_dict = checkpoint['model']
                else:
                    state_dict = checkpoint
            else:
                state_dict = checkpoint
            
            # í˜„ì¬ ëª¨ë¸ì˜ state_dict
            model_dict = self.x3d.state_dict()
            
            # Headë¥¼ ì œì™¸í•œ ê°€ì¤‘ì¹˜ë§Œ í•„í„°ë§
            pretrained_dict = {}
            for k, v in state_dict.items():
                # head/classifier ê´€ë ¨ ë ˆì´ì–´ ì œì™¸
                if any(skip in k for skip in ['head', 'proj', 'fc', 'classifier']):
                    continue
                
                # í‚¤ ì´ë¦„ ë§¤ì¹­ ì‹œë„
                clean_key = k.replace('module.', '')  # DDP ë˜í•‘ ì œê±°
                
                if clean_key in model_dict:
                    if model_dict[clean_key].shape == v.shape:
                        pretrained_dict[clean_key] = v
                    else:
                        print(f"   Shape mismatch for {clean_key}: {v.shape} vs {model_dict[clean_key].shape}")
                elif 'blocks.' in clean_key and clean_key in model_dict:
                    # blocks.0.xxx í˜•íƒœ ì²˜ë¦¬
                    if model_dict[clean_key].shape == v.shape:
                        pretrained_dict[clean_key] = v
            
            # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
            model_dict.update(pretrained_dict)
            self.x3d.load_state_dict(model_dict, strict=False)
            
            print(f"âœ… Successfully loaded X3D-{version.upper()} pretrained weights")
            print(f"   Loaded {len(pretrained_dict)}/{len(model_dict)} parameters")
            
            # ë¡œë“œëœ ì£¼ìš” ë¸”ë¡ í™•ì¸
            loaded_blocks = set()
            for k in pretrained_dict.keys():
                if 'blocks.' in k:
                    block_num = k.split('.')[1]
                    loaded_blocks.add(block_num)
            if loaded_blocks:
                print(f"   Loaded blocks: {sorted(loaded_blocks)}")
            
        except Exception as e:
            print(f"âŒ Error loading pretrained weights: {e}")
            print("   Using random initialization")
    
    def forward(self, t1, t2):
        """
        Args:
            t1: Time 1 ì´ë¯¸ì§€ [B, 3, H, W]
            t2: Time 2 ì´ë¯¸ì§€ [B, 3, H, W]
        Returns:
            change_map: [B, num_classes, H, W]
        """
        B, C, H, W = t1.shape
        
        # 1. Perception Frame í™•ì¥
        P = self.perception_frame.expand(B, -1, -1, -1)
        
        # 2. ë¹„ë””ì˜¤ êµ¬ì„±: [I1, P, I2]
        # X3DëŠ” [B, C, T, H, W] í˜•ì‹ í•„ìš”
        video = torch.stack([t1, P, t2], dim=2)  # [B, 3, 3, H, W]
        
        # 3. X3D Backboneìœ¼ë¡œ íŠ¹ì§• ì¶”ì¶œ
        x = video
        for i, block in enumerate(self.x3d.blocks):
            x = block(x)
        # x: [B, C_out, T', H', W'] (ê³µê°„/ì‹œê°„ ì°¨ì› ì¶•ì†Œë¨)
        
        # 4. Temporal Convë¡œ Perception Feature ê°•ì¡°
        x = self.temporal_conv(x)  # [B, 256, T', H', W']
        
        # 5. Perception Feature ì¶”ì¶œ (ì¤‘ê°„ time frame)
        # Perception Frameì˜ íŠ¹ì§•ì„ ì¶”ì¶œ
        t_mid = x.size(2) // 2
        perception_feat = x[:, :, t_mid, :, :]  # [B, 256, H', W']
        
        # 6. ë³€í™” ë§µ ìƒì„±
        change = self.head(perception_feat)  # [B, num_classes, H', W']
        
        # 7. ì›ë³¸ í¬ê¸°ë¡œ ë³µì›
        change_map = F.interpolate(
            change, 
            size=(H, W), 
            mode='bilinear', 
            align_corners=False
        )
        
        return change_map


class Change3DXS(Change3DBase):
    """
    Change3D with X3D-XS (eXtra Small)
    - Width Factor: 0.5
    - Depth Factor: 2.2
    - ê°€ì¥ ì‘ê³  ë¹ ë¥¸ ë²„ì „
    """
    def __init__(self, num_classes=1):
        super().__init__(
            num_classes=num_classes,
            width_factor=0.5,
            depth_factor=2.2,
            x3d_out_dim=48,  # 0.5 * 96
            version='xs'
        )


class Change3DS(Change3DBase):
    """
    Change3D with X3D-S (Small)
    - Width Factor: 1.0
    - Depth Factor: 1.0
    - ì‘ê³  íš¨ìœ¨ì ì¸ ë²„ì „
    """
    def __init__(self, num_classes=1):
        super().__init__(
            num_classes=num_classes,
            width_factor=1.0,
            depth_factor=1.0,
            x3d_out_dim=96,
            version='s'
        )


class Change3DM(Change3DBase):
    """
    Change3D with X3D-M (Medium)
    - Width Factor: 1.5
    - Depth Factor: 2.9
    - ê· í˜•ì¡íŒ ì¤‘ê°„ ë²„ì „
    """
    def __init__(self, num_classes=1):
        super().__init__(
            num_classes=num_classes,
            width_factor=1.5,
            depth_factor=2.9,
            x3d_out_dim=144,  # 1.5 * 96
            version='m'
        )


class Change3DL(Change3DBase):
    """
    Change3D with X3D-L (Large)
    - Width Factor: 2.0
    - Depth Factor: 5.0
    - ê°€ì¥ í¬ê³  ì •í™•í•œ ë²„ì „ (ê¸°ë³¸ê°’)
    """
    def __init__(self, num_classes=1):
        super().__init__(
            num_classes=num_classes,
            width_factor=2.0,
            depth_factor=5.0,
            x3d_out_dim=192,
            version='l'
        )


# ê¸°ë³¸ Change3D í´ë˜ìŠ¤ (í•˜ìœ„ í˜¸í™˜ì„±)
class Change3D(Change3DL):
    """ê¸°ë³¸ Change3D = Change3DL (Large ë²„ì „)"""
    pass


if __name__ == "__main__":
    print("="*60)
    print("Change3D with X3D Backbone (Multiple Versions)")
    print("="*60)
    
    # ê° ë²„ì „ë³„ í…ŒìŠ¤íŠ¸
    versions = [
        ('XS', Change3DXS),
        ('S', Change3DS),
        ('M', Change3DM),
        ('L', Change3DL)
    ]
    
    print("\n" + "="*60)
    print("Model Comparison")
    print("="*60)
    print(f"{'Version':<10} {'Parameters':<15} {'Size (MB)':<12}")
    print("-"*60)
    
    for name, ModelClass in versions:
        model = ModelClass(num_classes=1)
        model.eval()
        
        # íŒŒë¼ë¯¸í„° ê³„ì‚°
        total_params = sum(p.numel() for p in model.parameters())
        param_size = total_params * 4 / 1024 / 1024  # FP32
        
        print(f"{name:<10} {total_params/1e6:>10.2f}M     {param_size:>8.1f} MB")
    
    print("="*60)
    
    # X3D-Lë¡œ forward pass í…ŒìŠ¤íŠ¸
    print("\nTesting Change3DL (default)...")
    model = Change3DL(num_classes=1)
    model.eval()
    
    t1 = torch.randn(2, 3, 256, 256)
    t2 = torch.randn(2, 3, 256, 256)
    
    with torch.no_grad():
        output = model(t1, t2)
    
    print(f"Input: {t1.shape}")
    print(f"Output: {output.shape}")
    print("\nâœ… All Change3D versions ready!")