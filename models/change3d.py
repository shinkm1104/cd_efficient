"""
Change3D with X3D Backbone
X3D ë°±ë³¸ì„ ì‚¬ìš©í•œ ê°•ë ¥í•œ Video Modeling for Change Detection
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import os
from pathlib import Path

# X3D ë°±ë³¸ import
from models.x3d import create_x3d


class Change3DX3D(nn.Module):
    """
    X3D ë°±ë³¸ì„ ì‚¬ìš©í•œ Change3D ë„¤íŠ¸ì›Œí¬
    
    í•µì‹¬ ì•„ì´ë””ì–´:
    1. Perception Frame (í•™ìŠµ ê°€ëŠ¥í•œ "ê´€ì°°ì")
    2. X3D Backbone (ê°•ë ¥í•œ ë¹„ë””ì˜¤ íŠ¹ì§• ì¶”ì¶œ)
    3. Time ì°¨ì›ì—ì„œ Perception Feature ì¶”ì¶œ
    """
    
    def __init__(self, num_classes=1, x3d_version='l', pretrained=True):
        super(Change3DX3D, self).__init__()
        
        # ğŸ¯ í•µì‹¬ 1: Perception Frame
        self.perception_frame = nn.Parameter(
            torch.randn(1, 3, 256, 256) * 0.02
        )
        
        # ğŸ¯ í•µì‹¬ 2: X3D Backbone ì„¤ì •
        if x3d_version.lower() == 'l':
            # X3D-L ì„¤ì • (Large ë²„ì „)
            self.x3d = create_x3d(
                input_channel=3,
                input_clip_length=3,  # [I1, P, I2] = 3 frames
                input_crop_size=256,
                model_num_class=400,  # Kinetics-400 (ê°€ì¤‘ì¹˜ í˜¸í™˜ì„±)
                width_factor=2.0,
                depth_factor=5.0,  # X3D-Lì˜ í•µì‹¬: depthê°€ 5ë°°
                dropout_rate=0.5,
                head_output_with_global_average=False
            )
            x3d_out_dim = 192  # X3D-Lì˜ ì¶œë ¥ ì°¨ì›
            
        elif x3d_version.lower() == 'xs':
            # X3D-XS ì„¤ì • (eXtra Small ë²„ì „)
            self.x3d = create_x3d(
                input_channel=3,
                input_clip_length=3,
                input_crop_size=256,
                model_num_class=400,
                width_factor=2.0,
                depth_factor=2.2,  # X3D-XSëŠ” 2.2ë°°
                dropout_rate=0.5,
                head_output_with_global_average=False
            )
            x3d_out_dim = 192  # X3D-XSì˜ ì¶œë ¥ ì°¨ì›
        else:
            raise ValueError(f"Unknown X3D version: {x3d_version}")
        
        # ğŸ”¥ ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°
        if pretrained:
            self.load_pretrained_weights(x3d_version)
        
        # X3Dì˜ head ì œê±° (ë°±ë³¸ë§Œ ì‚¬ìš©)
        self.x3d.blocks = self.x3d.blocks[:-1]  # classification head ì œê±°
        
        # ğŸ¯ í•µì‹¬ 3: ë³€í™” íƒì§€ í—¤ë“œ
        # Time ì°¨ì› ì²˜ë¦¬ë¥¼ ìœ„í•œ Conv3D
        self.temporal_conv = nn.Conv3d(
            x3d_out_dim, 256,
            kernel_size=(3, 1, 1),  # Timeì¶•ë§Œ ì²˜ë¦¬
            padding=(1, 0, 0)
        )
        
        # ìµœì¢… ë³€í™” ë§µ ìƒì„± í—¤ë“œ
        self.head = nn.Sequential(
            nn.Conv2d(256, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, num_classes, kernel_size=1)
        )
    
    def load_pretrained_weights(self, version='l'):
        """ì‚¬ì „í•™ìŠµëœ X3D ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°"""
        # ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ
        weight_path = f'./pretrained/Change3D/X3D_{version.upper()}.pyth'
        
        if not os.path.exists(weight_path):
            print(f"âš ï¸ Warning: Pretrained weights not found at {weight_path}")
            print("   Using random initialization")
            print(f"   Download weights from: https://dl.fbaipublicfiles.com/pytorchvideo/x3d/x3d_{version}.pyth")
            return
        
        try:
            print(f"Loading pretrained weights from {weight_path}...")
            
            # ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°
            checkpoint = torch.load(weight_path, map_location='cpu')
            
            # checkpoint êµ¬ì¡° í™•ì¸
            if isinstance(checkpoint, dict):
                if 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                elif 'model_state' in checkpoint:
                    state_dict = checkpoint['model_state']
                elif 'model' in checkpoint:
                    state_dict = checkpoint['model']
                else:
                    state_dict = checkpoint
            else:
                state_dict = checkpoint
            
            # í˜„ì¬ ëª¨ë¸ì˜ state_dict
            model_dict = self.x3d.state_dict()
            
            # Headë¥¼ ì œì™¸í•œ ê°€ì¤‘ì¹˜ë§Œ í•„í„°ë§
            pretrained_dict = {}
            for k, v in state_dict.items():
                # head/classifier ê´€ë ¨ ë ˆì´ì–´ ì œì™¸
                if any(skip in k for skip in ['head', 'proj', 'fc', 'classifier']):
                    continue
                
                # í‚¤ ì´ë¦„ ë§¤ì¹­ ì‹œë„
                clean_key = k.replace('module.', '')  # DDP ë˜í•‘ ì œê±°
                
                if clean_key in model_dict:
                    if model_dict[clean_key].shape == v.shape:
                        pretrained_dict[clean_key] = v
                    else:
                        print(f"   Shape mismatch for {clean_key}: {v.shape} vs {model_dict[clean_key].shape}")
                elif 'blocks.' in clean_key and clean_key in model_dict:
                    # blocks.0.xxx í˜•íƒœ ì²˜ë¦¬
                    if model_dict[clean_key].shape == v.shape:
                        pretrained_dict[clean_key] = v
            
            # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
            model_dict.update(pretrained_dict)
            self.x3d.load_state_dict(model_dict, strict=False)
            
            print(f"âœ… Successfully loaded X3D-{version.upper()} pretrained weights")
            print(f"   Loaded {len(pretrained_dict)}/{len(model_dict)} parameters")
            
            # ë¡œë“œëœ ì£¼ìš” ë¸”ë¡ í™•ì¸
            loaded_blocks = set()
            for k in pretrained_dict.keys():
                if 'blocks.' in k:
                    block_num = k.split('.')[1]
                    loaded_blocks.add(block_num)
            if loaded_blocks:
                print(f"   Loaded blocks: {sorted(loaded_blocks)}")
            
        except Exception as e:
            print(f"âŒ Error loading pretrained weights: {e}")
            print("   Using random initialization")
    
    def forward(self, t1, t2):
        """
        Args:
            t1: Time 1 ì´ë¯¸ì§€ [B, 3, H, W]
            t2: Time 2 ì´ë¯¸ì§€ [B, 3, H, W]
        Returns:
            change_map: [B, num_classes, H, W]
        """
        B, C, H, W = t1.shape
        
        # 1. Perception Frame í™•ì¥
        P = self.perception_frame.expand(B, -1, -1, -1)
        
        # 2. ë¹„ë””ì˜¤ êµ¬ì„±: [I1, P, I2]
        # X3DëŠ” [B, C, T, H, W] í˜•ì‹ í•„ìš”
        video = torch.stack([t1, P, t2], dim=2)  # [B, 3, 3, H, W]
        
        # 3. X3D Backboneìœ¼ë¡œ íŠ¹ì§• ì¶”ì¶œ
        x = video
        for i, block in enumerate(self.x3d.blocks):
            x = block(x)
        # x: [B, C_out, T', H', W'] (ê³µê°„/ì‹œê°„ ì°¨ì› ì¶•ì†Œë¨)
        
        # 4. Temporal Convë¡œ Perception Feature ê°•ì¡°
        x = self.temporal_conv(x)  # [B, 256, T', H', W']
        
        # 5. Perception Feature ì¶”ì¶œ (ì¤‘ê°„ time frame)
        # Perception Frameì˜ íŠ¹ì§•ì„ ì¶”ì¶œ
        t_mid = x.size(2) // 2
        perception_feat = x[:, :, t_mid, :, :]  # [B, 256, H', W']
        
        # 6. ë³€í™” ë§µ ìƒì„±
        change = self.head(perception_feat)  # [B, num_classes, H', W']
        
        # 7. ì›ë³¸ í¬ê¸°ë¡œ ë³µì›
        change_map = F.interpolate(
            change, 
            size=(H, W), 
            mode='bilinear', 
            align_corners=False
        )
        
        return change_map


# ê¸°ë³¸ Change3D í´ë˜ìŠ¤ (ê°„ë‹¨í•œ ì¸í„°í˜ì´ìŠ¤)
class Change3D(nn.Module):
    """ê¸°ë³¸ Change3D - X3D-L ì‚¬ìš©"""
    
    def __init__(self, num_classes=1):
        super(Change3D, self).__init__()
        # X3D-Lì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš© (ê°€ì¤‘ì¹˜ ìˆìŒ)
        self.model = Change3DX3D(
            num_classes=num_classes,
            x3d_version='l',  # Large ë²„ì „
            pretrained=True   # ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ ì‚¬ìš©
        )
    
    def forward(self, t1, t2):
        return self.model(t1, t2)


if __name__ == "__main__":
    print("="*60)
    print("Change3D with X3D-L Backbone (Pretrained)")
    print("="*60)
    
    # X3D-L ë²„ì „ í…ŒìŠ¤íŠ¸
    print("\nInitializing Change3D with X3D-L...")
    model = Change3DX3D(num_classes=1, x3d_version='l', pretrained=True)
    
    # ëª¨ë¸ì„ evaluation ëª¨ë“œë¡œ
    model.eval()
    
    # í…ŒìŠ¤íŠ¸ ì…ë ¥
    t1 = torch.randn(2, 3, 256, 256)
    t2 = torch.randn(2, 3, 256, 256)
    
    print(f"\nInput shapes:")
    print(f"  t1: {t1.shape}")
    print(f"  t2: {t2.shape}")
    
    # Forward pass
    with torch.no_grad():
        output = model(t1, t2)
    
    print(f"\nOutput shape:")
    print(f"  change_map: {output.shape}")
    
    # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\nModel Parameters:")
    print(f"  Total: {total_params/1e6:.1f}M")
    print(f"  Trainable: {trainable_params/1e6:.1f}M")
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ì¶”ì •)
    param_size = total_params * 4 / 1024 / 1024  # FP32 ê¸°ì¤€
    print(f"  Estimated size: {param_size:.1f} MB (FP32)")
    
    print("\nâœ… Change3D with X3D-L ready for training!")
    print("   - Perception Frame: Learning temporal changes")
    print("   - X3D-L Backbone: Powerful spatiotemporal features")
    print("   - Pretrained: Kinetics-400 initialization")